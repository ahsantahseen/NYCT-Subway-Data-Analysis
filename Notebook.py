# %% [markdown]
# # Data Importing

# %%
from geodatasets import get_path
from folium import Map
from folium.plugins import HeatMap
from math import radians, sin, cos, sqrt, atan2
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick
import matplotlib.ticker as ticker
from shapely import wkt
import geopandas as gpd
from shapely.geometry import Point
import torch
import torch.nn as nn
import torch.optim as optim

# %%
df = pd.read_csv(
    'MTA_Subway_Hourly_Ridership__Beginning_2025_20250402.csv', low_memory=False)

# %% [markdown]
# ### Describing our data

# %%
df.info()

# %%
print(df['payment_method'].unique())
print(df['fare_class_category'].unique())

# %%
print("Total $USD Revenue Generated by MTA NYCT Subway in 2025 (Jan 1st - April 1st ): ",
      df['ridership'].sum()*2.90)
print(df['transfers'].sum())

# %% [markdown]
# # Data Cleaning

# %% [markdown]
# ### Checking any nulls in our dataset

# %%
df.isnull().sum()

# %% [markdown]
# > As we can see that, there's no nulls in our database, most of the government agencies datasets are pre-cleaned.

# %% [markdown]
# ### Coverting timestamp into datetime and extracting day, time and month as individual columns

# %%
df['transit_timestamp'] = pd.to_datetime(df['transit_timestamp'])
df['day'] = df['transit_timestamp'].dt.day
df['time'] = df['transit_timestamp'].dt.time
df['month'] = df['transit_timestamp'].dt.month
df['hour'] = df['transit_timestamp'].dt.hour
df['date'] = df['transit_timestamp'].dt.date
df['weekday'] = df['transit_timestamp'].dt.day_name()

# %%
# Convert WKT string to shapely geometry and extract coords
df['geometry'] = df['Georeference'].apply(wkt.loads)
df['longitude'] = df['geometry'].apply(lambda p: p.x)
df['latitude'] = df['geometry'].apply(lambda p: p.y)

# %% [markdown]
# ## Data Exploration

# %%
df[['month', 'ridership']].groupby('month').sum()

# %%
df[['ridership', 'payment_method']].groupby(['payment_method']).sum()

# %%
df.groupby(['borough', 'payment_method'])[
    'ridership'].sum().apply(lambda x: f"{x:,.0f}")

# %%
df.groupby(['borough'])[
    'ridership'].sum().sort_values(ascending=False).apply(lambda x: f"{x:,.0f}")

# %%
df.groupby(['borough', 'station_complex'])['ridership'].sum(
).sort_values(ascending=False).apply(lambda x: f"{x:,.0f}")

# %%
df.groupby(['transit_timestamp'])[
    'ridership'].sum().sort_values(ascending=False).head(5).apply(lambda x: f"{x:,.0f}")

# %%
df.groupby(['transit_timestamp'])[
    'ridership'].sum().sort_values(ascending=False).tail(5).apply(lambda x: f"{x:,.0f}")

# %%
df.groupby(['station_complex'])['ridership'].sum().sort_values(
    ascending=False).head(5).apply(lambda x: f"{x:,.0f}")

# %%
df.groupby(['station_complex'])['ridership'].sum(
).sort_values(ascending=False).tail(5).apply(lambda x: f"{x:,.0f}")

# %% [markdown]
# ## Feature Selection

# %%

# 1. Encode the categorical columns
df_encoded = df.copy().drop(
    ['transit_mode', 'station_complex_id', 'transit_timestamp'], axis=1)
label_cols = ['borough', 'station_complex',
              'fare_class_category', 'payment_method']
for col in label_cols:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])

df_encoded.head()

# 2. Select only numeric columns (after encoding!)
numeric_df = df_encoded.select_dtypes(include='number')

# 3. Compute full correlation matrix
corr_matrix = numeric_df.corr()

# 4. Focus only on correlation with 'ridership'
ridership_corr = corr_matrix['ridership'].sort_values(ascending=False)

# 6. Optional: full heatmap
plt.figure(figsize=(16, 10))
sns.heatmap(corr_matrix, cmap='coolwarm', center=0, linewidths=0.5, annot=True)
plt.title("Correlation Matrix (Encoded Categorical + Numeric Features)", fontsize=16)
plt.xticks(rotation=45)
plt.show()

# %% [markdown]
# | Feature             | Correlation with Ridership |
# |---------------------|----------------------------|
# | transfers           | 0.352819                   |
# | payment_method      | 0.153978                   |
# | fare_class_category | 0.090092                   |
# | borough             | 0.070058                   |
# | latitude            | 0.014912                   |
# | station_complex     | -0.021479                  |
# | longitude           | -0.076470                  |

# %% [markdown]
# > We will select transfers, payment_method and fare_class_category as our features

# %%
new_df = df[['month', 'transfers', 'payment_method',
             'fare_class_category', 'ridership']]

# %%
monthly_ridership = new_df[['month', 'ridership']
                           ].groupby('month').sum().reset_index()

# %%
le_payment = LabelEncoder()
le_fare = LabelEncoder()

new_df['payment_method'] = le_payment.fit_transform(new_df['payment_method'])
new_df['fare_class_category'] = le_fare.fit_transform(
    new_df['fare_class_category'])
monthly_features = new_df.groupby('month')[
    ['transfers', 'payment_method', 'fare_class_category']].sum().reset_index()

# Merge
monthly_df = new_df.groupby('month').agg({
    'transfers': 'sum',         # sum because more transfers → more ridership
    'payment_method': 'mean',   # mean because it's a category
    'fare_class_category': 'mean',  # mean because it's a category
    'ridership': 'sum'          # sum of ridership
}).reset_index()

print("Monthly data:")
print(monthly_df)

# Prepare Input (X) and Target (y)
# -----------------
# Predict next month's ridership
monthly_df['target_ridership'] = monthly_df['ridership'].shift(-1)

# Drop the last row (no target available)
monthly_df = monthly_df.dropna()
print(monthly_df)

X = monthly_df[['transfers', 'payment_method', 'fare_class_category']].values
y = monthly_df['target_ridership'].values

# Convert to torch tensors
X_tensor = torch.tensor(X, dtype=torch.float32)
y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)


# Define Model

class LinearRegressionModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(LinearRegressionModel, self).__init__()
        self.linear = nn.Linear(input_dim, output_dim)

    def forward(self, x):
        return self.linear(x)


model = LinearRegressionModel(input_dim=3, output_dim=1)

# Train Model
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

epochs = 500
for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    outputs = model(X_tensor)
    loss = criterion(outputs, y_tensor)
    loss.backward()
    optimizer.step()


# Predict Next Month
# -----------------
model.eval()
with torch.no_grad():
    # Use the latest available month's features
    prediction = model(X_tensor[-1].unsqueeze(0))
    print(f"Predicted ridership for the next month: {prediction.item():,.2f}")

# %%
preds = model(X_tensor).detach().numpy()
plt.plot(monthly_df['month'], y, label='Actual')
plt.plot(monthly_df['month'], preds, label='Predicted')
plt.xticks(rotation=45)
plt.legend()
plt.title('Actual vs Predicted Ridership')
plt.ylabel('Ridership')
plt.show()

# %% [markdown]
# # Data Visualization

# %%


def auto_format_large(x, pos):
    if x >= 1e9:
        return f'{x * 1e-9:.1f}B'
    elif x >= 1e6:
        return f'{x * 1e-6:.1f}M'
    else:
        return f'{x:,.0f}'

# %% [markdown]
# #### 0a. Which Subway Stations are the most busiest? (or in simpler terms which station has the most people entering)


# %%
riderships_by_subway_stations = df.groupby(['borough', 'station_complex'])[
    'ridership'].sum().sort_values(ascending=False)
riderships_by_subway_stations
top_5_busiest_subways = riderships_by_subway_stations.head(5).reset_index()
top_5_busiest_subways['short_station'] = top_5_busiest_subways['station_complex'].str[:15]
plt.figure(figsize=[10, 5])
plt.gca().yaxis.set_major_formatter(mtick.FuncFormatter(auto_format_large))
ax = sns.barplot(data=top_5_busiest_subways, x="short_station",
                 y="ridership", hue="short_station", palette="Set2")
plt.xlabel("Subway Station")
plt.ylabel("Total Riders")
plt.title("Top 5 Busiest Subway Stations")
plt.xticks(rotation=45)
for bar in ax.patches:
    height = bar.get_height()
    ax.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        auto_format_large(height, None),
        ha='center', va='bottom',
        fontsize=8
    )
plt.show()

# %% [markdown]
# #### 0b. Which Subway Stations are the most busiest? (or in simpler terms which station has the most people entering)

# %%
top_5_less_used_subways = riderships_by_subway_stations.tail(5).reset_index()
top_5_less_used_subways['short_station'] = top_5_less_used_subways['station_complex'].str[:15]
plt.figure(figsize=[10, 5])
plt.gca().yaxis.set_major_formatter(mtick.FuncFormatter(auto_format_large))
ax = sns.barplot(data=top_5_less_used_subways, x="short_station",
                 y="ridership", hue="short_station", palette="Set2")
plt.xlabel("Subway Station")
plt.ylabel("Total Riders")
plt.title("Top 5 Less Used Subway Stations")
plt.xticks(rotation=45)
for bar in ax.patches:
    height = bar.get_height()
    ax.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        auto_format_large(height, None),
        ha='center', va='bottom',
        fontsize=8
    )
plt.show()

# %% [markdown]
# > We will be discussing various trends, answering some questions that have been collected from observers

# %% [markdown]
# ##### 1. Are New Yorkers finally switching to OMNY? (Compare ridership between Metro and Omni)
#

# %%
# First we select the relevant data from our columns
payment_method_df = df[['ridership', 'payment_method']
                       ].groupby(['payment_method']).sum().reset_index()
# Then we calculate the ratio of the ridership by payment method
total_ridership = payment_method_df['ridership'].sum()
payment_method_df['ridership_ratio'] = payment_method_df['ridership'] / \
    total_ridership * 100
# Then we plot the bar
plt.figure(figsize=[4, 6])
sns.barplot(data=payment_method_df, x='payment_method',
            y='ridership_ratio', palette='Set2')
plt.xlabel('Payment Method')
plt.ylabel('Ridership')
plt.title('Ridership by Payment Method (OMNY vs Metrocard)')
plt.show()

# %% [markdown]
# > Let's compare it month-by-month

# %%
payment_method_per_month = df[['month', 'ridership', 'payment_method']].groupby(
    ['month', 'payment_method'])['ridership'].sum().reset_index()
print(payment_method_per_month)
plt.figure(figsize=[10, 5])
ax = sns.barplot(data=payment_method_per_month, x='month', y='ridership',
                 hue='payment_method', palette='Set2')
plt.gca().yaxis.set_major_formatter(mtick.FuncFormatter(auto_format_large))
plt.title('Ridership by Payment Method (Month-wise)')
plt.xlabel('Month')
plt.ylabel('Ridership (in millions)')
plt.tight_layout()
for bar in ax.patches:
    height = bar.get_height()
    ax.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        auto_format_large(height, None),
        ha='center', va='bottom',
        fontsize=8
    )
plt.show()

# %% [markdown]
# > Lets compare it borough-wise

# %%
# Grouping by payment method and borough
payment_method_per_month = df[['ridership', 'payment_method', 'borough']].groupby(
    ['payment_method', 'borough'])['ridership'].sum().reset_index()

plt.figure(figsize=[10, 6])
ax = sns.barplot(data=payment_method_per_month, x='borough', y='ridership',
                 hue='payment_method', palette='Set2')

# Log scale for readability
plt.gca().yaxis.set_major_formatter(mtick.FuncFormatter(auto_format_large))

# Labels and title
plt.title('Ridership by Payment Method (Borough-wise)')
plt.xlabel('Borough')
plt.ylabel('Ridership')
plt.tight_layout()

# Add labels on each bar
for bar in ax.patches:
    height = bar.get_height()
    ax.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        auto_format_large(height, None),
        ha='center', va='bottom',
        fontsize=8
    )
plt.show()

# %% [markdown]
# #### 2. Are no. of transfers available directly proportional to the ridership values?

# %%
correlation = df['ridership'].corr(df['transfers'])
print(f'Correlation between ridership and transfers: {correlation:.2f}')

# %% [markdown]
# - 	A value of 0.3 means there’s a weak positive correlation between number of transfers and ridership.
# -	It suggests that as the number of transfers increases, ridership tends to increase slightly, but the relationship is not very strong or direct.
# -	It’s not directly proportional (which would be close to 1.0), but there is some loose upward trend.
#

# %%
plt.figure(figsize=(8, 6))
sns.scatterplot(data=df, x='transfers', y='ridership')

plt.title('Ridership vs. Number of Transfers')
plt.xlabel('Number of Transfers')
plt.ylabel('Ridership')
plt.tight_layout()
plt.show()

# %% [markdown]
# #### 3. Which borough has the most ridership (paid) compared to their population (get population from external factors, discuss social problems or fare evasion)
# 	Borough-wise ridership
# 	Borough-wise earnings by the MTA

# %%
# 1) Prepare your data
bw = borough_wise_ridership.copy()
bw['population_m'] = bw['population'] / 1e6     # in millions
bw['earnings_m'] = bw['earnings'] / 1e6     # in millions of dollars
bw = bw.sort_values('population_m', ascending=False)

# 2) Plot bars for population
fig, ax1 = plt.subplots(figsize=(10, 6))
pop_bars = ax1.bar(
    bw.index,
    bw['population_m'],
    color='skyblue',
    label='Population (millions)'
)
ax1.set_ylabel('Population (millions)', fontsize=12)
ax1.set_ylim(0, bw['population_m'].max()*1.1)

# 3) Twin axis for earnings
ax2 = ax1.twinx()
earn_line = ax2.plot(
    bw.index,
    bw['earnings_m'],
    color='salmon',
    marker='o',
    linewidth=2,
    label='Earnings ($ millions)'
)
ax2.set_ylabel('Earnings ($ millions)', fontsize=12)
ax2.set_ylim(0, bw['earnings_m'].max()*1.1)
ax1.set_title('NYC Borough Population vs. Earnings', fontsize=14, pad=15)
ax1.grid(axis='y', linestyle='--', alpha=0.5)
ax1.set_xticklabels(bw.index, rotation=30, ha='right')
h1, l1 = ax1.get_legend_handles_labels()
h2, l2 = ax2.get_legend_handles_labels()
ax1.legend(h1+h2, l1+l2, loc='upper left')

plt.tight_layout()
plt.show()

# %%
print(df[['ridership', 'payment_method']].groupby(['payment_method']).sum())

# %% [markdown]
# #### 5. Most busiest hour of the 2025

# %%
# Group by hour
hourly_ridership = df.groupby('hour')['ridership'].sum()

# Find the busiest hour
busiest_hour = hourly_ridership.idxmax()
busiest_ridership = hourly_ridership.max()

# Output result
print(f"Busiest hour: {busiest_hour}:00 with {busiest_ridership:,} riders")

# %% [markdown]
# #### 6. Most busiest day of the week in the 2025

# %%
# Group by weekday
daily_ridership = df.groupby('weekday')['ridership'].sum()

# Reorder weekdays (optional, for correct order in plots)
weekday_order = ['Monday', 'Tuesday', 'Wednesday',
                 'Thursday', 'Friday', 'Saturday', 'Sunday']
daily_ridership = daily_ridership.reindex(weekday_order)

# Find the busiest day
busiest_day = daily_ridership.idxmax()
busiest_ridership = daily_ridership.max()

# Output result
print(f"Busiest Day: {busiest_day} with {busiest_ridership:,} riders")

# %% [markdown]
# #### 6. Most busiest date in the 2025

# %%
# Group by hour
yearly_ridership = df.groupby('date')['ridership'].sum()

# Find the busiest hour
busiest_day = yearly_ridership.idxmax()
busiest_ridership = yearly_ridership.max()

# Output result
print(f"Busiest day: {busiest_day} with {busiest_ridership:,} riders")

# %%

# %%
# Group by hour
hourly_ridership = df.groupby('hour')['ridership'].sum()

# Find the busiest hour
busiest_hour = hourly_ridership.idxmax()
busiest_ridership = hourly_ridership.max()

# Output result
print(f"Busiest hour: {busiest_hour}:00 with {busiest_ridership:,} riders")

# %%
# Haversine formula to calculate distance


def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # Radius of the Earth in km
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])

    dlat = lat2 - lat1
    dlon = lon2 - lon1

    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))

    return R * c  # Distance in kilometers


# %%
# Calculate distance from Midtown Manhattan for each station
midtown_coords = [40.754, -73.984]
df['distance_from_midtown'] = df.apply(
    lambda row: haversine(row['latitude'], row['longitude'], midtown_coords[0], midtown_coords[1]), axis=1
)

# Group stations by distance range (e.g., 0-5 km, 5-10 km, etc.)
bins = [0, 5, 10, 15, 20, 25]
labels = ['0-5 km', '5-10 km', '10-15 km', '15-20 km', '20-25 km']
df['distance_range'] = pd.cut(
    df['distance_from_midtown'], bins=bins, labels=labels, right=False)

# Group by distance range and calculate average ridership
grouped_data = df.groupby('distance_range').agg(
    average_ridership=('ridership', 'mean')
).reset_index()

# Plotting the data
plt.figure(figsize=(10, 6))
sns.barplot(x='distance_range', y='average_ridership',
            data=grouped_data, palette='Set3')
plt.title('Average Ridership by Distance from Midtown Manhattan')
plt.xlabel('Distance from Midtown (km)')
plt.ylabel('Average Ridership')
plt.tight_layout()
plt.show()

# %%
df[['latitude', 'longitude']].dropna()

nyc_center = [40.754, -73.984]

m = Map(location=nyc_center, zoom_start=10,
        prefer_canvas=True, tiles='cartodbpositron')
heat_map_data = df[['latitude',
                    'longitude']].dropna().values.tolist()
heat_map = HeatMap(heat_map_data, radius=18).add_to(m)
m

# %%


# 1. Load your point data
# Make sure this has 'latitude', 'longitude', 'ridership'
geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]
points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')

# 2. Load NYC boundaries (built-in test: boroughs)
nyc = gpd.read_file(get_path('nybb'))
nyc = nyc.to_crs(points.crs)

# 3. Spatial join to assign each point to a polygon
joined = gpd.sjoin(points, nyc, how='left', predicate='within')

# 4. Group by area and sum ridership
ridership_sum = joined.groupby('BoroName')['ridership'].sum().reset_index()
nyc = nyc.merge(ridership_sum, on='BoroName', how='left')
nyc['ridership'] = nyc['ridership'].fillna(0)

# 5. Plot
fig, ax = plt.subplots(figsize=(10, 10))
nyc.plot(column='ridership', ax=ax, cmap='viridis',
         edgecolor='white', legend=True)
points.plot(ax=ax, color='black', markersize=10, alpha=0.6)

ax.set_title("NYC Ridership by Area", fontsize=16)
ax.axis('off')
plt.show()
